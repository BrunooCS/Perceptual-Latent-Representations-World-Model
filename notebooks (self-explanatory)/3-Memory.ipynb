{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d133e40",
   "metadata": {},
   "source": [
    "# Memory Model: MDN-RNN\n",
    "This notebook explains the architecture, training pipeline, and visualization of our MDN-RNN memory model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd6234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02566f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Get the absolute path to the parent directory of the notebook\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "path = str(Path().cwd().parent)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abf4ad",
   "metadata": {},
   "source": [
    "## 1. Data Preparation: CarRacingDataset\n",
    "\n",
    "The `CarRacingDataset` class is responsible for loading and preprocessing the data for training our RNN-MDN model. This dataset handles sequences of latent vectors that were previously extracted using a Variational Autoencoder (VAE).\n",
    "\n",
    "Key features:\n",
    "- Loads sequences of latent vectors from files\n",
    "- Creates input-output pairs for training sequence prediction\n",
    "- Handles time series data with sequence length parameter\n",
    "- Prepares batched data for efficient training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20016c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from src.utils.dataset import CarRacingDataset_RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a70d22c",
   "metadata": {},
   "source": [
    "## 2. RNN-MDN Model Architecture\n",
    "\n",
    "The RNN-MDN (Recurrent Neural Network with Mixture Density Network) is a powerful model that combines the sequence modeling capabilities of LSTMs with the distributional output of Mixture Density Networks. This architecture is ideal for our world model's memory component because:\n",
    "\n",
    "1. The LSTM component captures temporal dependencies in sequences of latent vectors\n",
    "2. The MDN component models the uncertainty in predicting future latent states\n",
    "\n",
    "<img src='imgs/rnn_mdn.png' width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9982d0",
   "metadata": {},
   "source": [
    "### Mixture Density Network (MDN)\n",
    "\n",
    "The MDN outputs parameters for a mixture of Gaussian distributions:\n",
    "\n",
    "- **π**: The mixture weights (which Gaussian to pick)\n",
    "- **μ**: The means of each Gaussian\n",
    "- **σ**: The standard deviations of each Gaussian\n",
    "\n",
    "For a mixture with K components and D-dimensional output:\n",
    "- π has shape [K]\n",
    "- μ has shape [K, D]\n",
    "- σ has shape [K, D]\n",
    "\n",
    "The probability density function is:\n",
    "\n",
    "$$p(y|x) = \\sum_{k=1}^{K} \\pi_k(x) \\mathcal{N}(y|\\mu_k(x), \\sigma_k^2(x))$$\n",
    "\n",
    "Where:\n",
    "- $\\pi_k(x)$ is the mixture weight for component k\n",
    "- $\\mathcal{N}(y|\\mu_k(x), \\sigma_k^2(x))$ is the Gaussian probability density for component k\n",
    "\n",
    "<img src='imgs/mdn.png' width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd894f",
   "metadata": {},
   "source": [
    "### Dream System Architecture\n",
    "\n",
    "The RNN-MDN model serves as the \"memory\" component in our World Model architecture. It predicts the next latent state based on the current latent state, action, and reward.\n",
    "\n",
    "In the dreaming mode, the model can generate sequences of latent states without real input, allowing the agent to \"imagine\" trajectories through the environment.\n",
    "\n",
    "<img src='imgs/dream_diagram.png' width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f15dd8",
   "metadata": {},
   "source": [
    "## 3. Training the RNN-MDN Model\n",
    "\n",
    "Training the RNN-MDN model involves minimizing the negative log-likelihood of the target latent vectors given the predicted mixture parameters. \n",
    "\n",
    "The loss function is derived from the probability density function of the mixture model:\n",
    "\n",
    "$$\\text{Loss} = -\\log\\left(\\sum_{k=1}^{K} \\pi_k \\mathcal{N}(y|\\mu_k, \\sigma_k^2)\\right)$$\n",
    "\n",
    "To prevent numerical underflow, we use the log-sum-exp trick:\n",
    "\n",
    "$$\\log\\sum_i e^{x_i} = a + \\log\\sum_i e^{x_i - a}$$\n",
    "\n",
    "where $a = \\max_i(x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb6b919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vision(\n",
       "  (unet1): UNet(\n",
       "    (inc): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up(\n",
       "      (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up(\n",
       "      (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv(\n",
       "      (conv): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (dds): DDS()\n",
       "  (downscaling): DownscalingEncoder(\n",
       "    (conv1): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): DownStride(\n",
       "      (down): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down2): DownStride(\n",
       "      (down): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down3): DownPool(\n",
       "      (down): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "      )\n",
       "    )\n",
       "    (conv4): OutConv(\n",
       "      (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (mini_vae): miniVAE(\n",
       "    (encoder): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DownStride(\n",
       "        (down): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): DownStride(\n",
       "        (down): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (fc_mu): Linear(in_features=4096, out_features=32, bias=True)\n",
       "    (fc_logvar): Linear(in_features=4096, out_features=32, bias=True)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=4096, bias=True)\n",
       "      (1): Unflatten(dim=1, unflattened_size=(256, 4, 4))\n",
       "      (2): UpStride(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): UpStride(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (upscaling): UpscalingDecoder(\n",
       "    (conv1): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up1): UpSample(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(size=(24, 24), mode='bilinear')\n",
       "      )\n",
       "    )\n",
       "    (conv4): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up2): UpStride(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv5): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up3): UpStride(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv(\n",
       "      (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (unet2): UNet(\n",
       "    (inc): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down(\n",
       "      (down): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up(\n",
       "      (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up(\n",
       "      (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): ConvBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv(\n",
       "      (conv): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.dds_vae import Vision\n",
    "\n",
    "# Instantiate model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vision = Vision(n_features_to_select=0.03, \n",
    "                in_ch=3, \n",
    "                out_ch=3, \n",
    "                base_ch=16, \n",
    "                alpha=1.0, \n",
    "                delta=0.1\n",
    ").to(device)\n",
    "vision.load_state_dict(torch.load(path+'/src/trained_models/vision_03_miniVAE.pth', map_location=device, weights_only=True))\n",
    "vision.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54983218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.mdn_rnn import MDNRNN\n",
    "\n",
    "memory = MDNRNN(latent_dim=32, \n",
    "                action_dim=3, \n",
    "                hidden_dim=256, \n",
    "                num_gaussians=5\n",
    ").to(device)\n",
    "\n",
    "memory.load_state_dict(torch.load(path+'/src/trained_models/memory.pth', map_location=device, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e44e6d",
   "metadata": {},
   "source": [
    "## 4. Dream Visualization with RNN-MDN\n",
    "\n",
    "In this section, we'll use the trained RNN-MDN model to generate \"dreams\" - sequences of latent vectors that are decoded back into images using the VAE decoder. This demonstrates how the model can imagine possible future states without real input.\n",
    "\n",
    "The process involves:\n",
    "1. Starting with an initial latent vector\n",
    "2. Using the RNN-MDN to predict the next latent vector\n",
    "3. Decoding the predicted latent vector into an image using the VAE\n",
    "4. Repeating the process to generate a sequence of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5733500",
   "metadata": {},
   "source": [
    "### **Predict next frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1439dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from src.utils.utils import TRANSFORM as transform\n",
    "from src.models.mdn_rnn import sample_mdn\n",
    "\n",
    "def run_car_racing_rnn_mda(env_name, vision, mdnrnn, transform, device, scale=1, resolution=(150, 150), tau =1.0):\n",
    "    \n",
    "    # Initialize pygame for rendering\n",
    "    pygame.init()\n",
    "    resolution = (resolution[0] * 2 * scale, resolution[1] * scale)\n",
    "    screen = pygame.display.set_mode(resolution)\n",
    "    clock = pygame.time.Clock() \n",
    "    \n",
    "    action = np.zeros(3)  # Initialize action array\n",
    "    \n",
    "    def get_action(keys):\n",
    "        \"\"\" Map keyboard input to actions \"\"\"\n",
    "        action[0] = -1.0 if keys[pygame.K_LEFT] else 1.0 if keys[pygame.K_RIGHT] else 0.0  # Steering\n",
    "        action[1] = 1.0 if keys[pygame.K_UP] else 0.0  # Accelerate\n",
    "        action[2] = 1.0 if keys[pygame.K_DOWN] else 0.0  # Brake\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    # Initialize the environment\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    running = True\n",
    "    h = mdnrnn.rnn.init_hidden(1) \n",
    "    h = (h[0].to(device), h[1].to(device))\n",
    "    \n",
    "    cnt = 0\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "        \n",
    "        keys = pygame.key.get_pressed()  # Get current key states\n",
    "        action = get_action(keys)        # Update action based on key presses\n",
    "\n",
    "        # Enviroment step \n",
    "        obs, reward, done, info, _ = env.step(action)\n",
    "        \n",
    "        # Render and process the frame\n",
    "        x = transform(obs).unsqueeze(0).to(device)  # Transform frame to tensor\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mask, mini_mask, z = vision.encode(x)           \n",
    "                \n",
    "            # Generate predicted next image  using RNN-MDA\n",
    "            action_tensor = torch.tensor(action, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "            pi, mu, sigma, h = mdnrnn(z.unsqueeze(0),action_tensor, h=h, tau=tau)\n",
    "            z_next = sample_mdn(pi, mu, sigma)\n",
    "            \n",
    "            # Decode MDN sampled latent vector\n",
    "            x_hat, mask_hat, mini_mask_hat =  vision.decode(z_next.squeeze(0))\n",
    "            reconstructed = x_hat\n",
    "\n",
    "        cnt+=1\n",
    "        \n",
    "        # Prepare images for display\n",
    "        reconstructed = (reconstructed.squeeze(0).permute(2, 1, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "        obs = (x.squeeze(0).permute(2, 1, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "        \n",
    "        # Concatenate original and reconstructed images\n",
    "        full_image = np.concatenate((obs, reconstructed), axis=0)\n",
    "        full_image_resized = cv2.resize(full_image, (resolution[1], resolution[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Display the combined image\n",
    "        clock.tick(30)\n",
    "        pygame.surfarray.blit_array(screen, full_image_resized)\n",
    "        pygame.display.flip()\n",
    "        \n",
    "        if done:\n",
    "            obs, _ = env.reset()  # Reset environment if done\n",
    "            h = mdnrnn.rnn.init_hidden(1) \n",
    "            h = (h[0].to(device), h[1].to(device))\n",
    "            \n",
    "    pygame.quit()\n",
    "    env.close()\n",
    "# \n",
    "\n",
    "run_car_racing_rnn_mda(env_name=\"CarRacing-v3\", vision=vision, mdnrnn=memory, transform=transform, device=device, scale=4, tau=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa36a6c",
   "metadata": {},
   "source": [
    "## **Dream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bdb7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from src.utils.utils import setup_video_writer\n",
    "\n",
    "def run_car_racing_rnn_mda(env_name, vision, mdnrnn, transform, device, scale=1, resolution=(150, 150), tau=1.0, video_filepath='renders/dream.mp4', save_video=False):\n",
    "    import pygame\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import cv2\n",
    "\n",
    "    # Initialize the environment\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    obs, _ = env.reset()\n",
    "    for _ in range(0):\n",
    "        env.step(np.array([0, 0, 0]))\n",
    "\n",
    "    # Initialize pygame for rendering\n",
    "    pygame.init()\n",
    "    resolution = (resolution[0] * scale, resolution[1] * scale)\n",
    "    screen = pygame.display.set_mode(resolution)\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    action = np.zeros(3)  # Initialize action array\n",
    "    video_writer = setup_video_writer(video_filepath, resolution[::-1]) if save_video else None\n",
    "\n",
    "    def get_action(keys):\n",
    "        \"\"\" Map keyboard input to actions \"\"\"\n",
    "        action[0] = -1.0 if keys[pygame.K_LEFT] else 1.0 if keys[pygame.K_RIGHT] else 0.0  # Steering\n",
    "        action[1] = 1.0 if keys[pygame.K_UP] else 0.0  # Accelerate\n",
    "        action[2] = 1.0 if keys[pygame.K_DOWN] else 0.0  # Brake\n",
    "        return action\n",
    "\n",
    "    running = True\n",
    "    h = mdnrnn.rnn.init_hidden(1)\n",
    "    h = (h[0].to(device), h[1].to(device))\n",
    "\n",
    "    cnt = 0\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        keys = pygame.key.get_pressed()  # Get current key states\n",
    "        action = get_action(keys)  # Update action based on key presses\n",
    "\n",
    "        # Environment step\n",
    "        obs, reward, done, info, _ = env.step(action)\n",
    "        obs_tensor = transform(obs).unsqueeze(0).to(device)  # Transform frame to tensor\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if cnt == 0:\n",
    "                mask, mini_mask, z = vision.encode(obs_tensor)\n",
    "                z = z.unsqueeze(0)\n",
    "            else:\n",
    "                z = z_next\n",
    "\n",
    "            action_tensor = torch.tensor(action, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            pi, mu, sigma, h = mdnrnn(z, action_tensor, h=h, tau=tau)\n",
    "            z_next = sample_mdn(pi, mu, sigma)\n",
    "\n",
    "            x_hat, mask_hat, mini_mask_hat = vision.decode(z_next.squeeze(0))\n",
    "            reconstructed = x_hat\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "        # Prepare the reconstructed image for display\n",
    "        reconstructed = (reconstructed.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "        reconstructed_resized = cv2.resize(reconstructed, (resolution[0], resolution[1]))\n",
    "\n",
    "        # Convert reconstructed image to pygame surface\n",
    "        frame_surface = pygame.surfarray.make_surface(reconstructed_resized.swapaxes(0, 1))\n",
    "\n",
    "        # Blit frame to the screen\n",
    "        screen.blit(frame_surface, (0, 0))\n",
    "\n",
    "        # Draw key indicators using pygame shapes\n",
    "        indicator_color = (255, 0, 0)  # Red color for indicators\n",
    "\n",
    "        # Left arrow (proportional size)\n",
    "        if keys[pygame.K_LEFT]:\n",
    "            pygame.draw.polygon(screen, indicator_color, [(40, resolution[1] - 40), (20, resolution[1] - 30), (40, resolution[1] - 20)])\n",
    "\n",
    "        # Right arrow (proportional size)\n",
    "        if keys[pygame.K_RIGHT]:\n",
    "            pygame.draw.polygon(screen, indicator_color, [(100, resolution[1] - 40), (120, resolution[1] - 30), (100, resolution[1] - 20)])\n",
    "\n",
    "        # Up arrow (centered and proportional)\n",
    "        if keys[pygame.K_UP]:\n",
    "            pygame.draw.polygon(screen, indicator_color, [(70, resolution[1] - 70), (50, resolution[1] - 50), (90, resolution[1] - 50)])\n",
    "\n",
    "        # Down arrow (proportional rectangle)\n",
    "        if keys[pygame.K_DOWN]:\n",
    "            pygame.draw.rect(screen, indicator_color, (140, resolution[1] - 60, 40, 40))\n",
    "\n",
    "        # Update the display\n",
    "        clock.tick(30)\n",
    "        pygame.display.flip()\n",
    "\n",
    "        if save_video and video_writer is not None:\n",
    "            video_writer.write(cv2.cvtColor(reconstructed_resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            h = mdnrnn.rnn.init_hidden(1)\n",
    "            h = (h[0].to(device), h[1].to(device))\n",
    "\n",
    "    pygame.quit()\n",
    "    env.close()\n",
    "\n",
    "    if save_video and video_writer is not None:\n",
    "        video_writer.release()\n",
    "\n",
    "\n",
    "run_car_racing_rnn_mda(env_name=\"CarRacing-v3\", vision=vision, mdnrnn=memory, transform=transform, device=device, scale=4, tau=.001, save_video=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
